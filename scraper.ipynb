{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import snscrape.modules.twitter as sntwitter\n",
    "import pandas as pd\n",
    "import glob\n",
    "import time\n",
    "from retrying import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "@retry(wait_random_min= 120000, wait_random_max = 600000)\n",
    "def get_tweets(username):\n",
    "    \n",
    "    localtime = time.asctime( time.localtime(time.time()) )\n",
    "    print(localtime, \"\\t\", f\"{username}\", end=\"ï¼š\")\n",
    "    \n",
    "    # Creating list to append tweet data to\n",
    "    tweets_list = []\n",
    "\n",
    "    # seting a max number\n",
    "    # max = 1\n",
    "\n",
    "    # Using TwitterSearchScraper to scrape data and append tweets to list\n",
    "    for i,tweet in enumerate(sntwitter.TwitterSearchScraper(f\"from:{username}\").get_items()):\n",
    "        # if i>max:\n",
    "            # break\n",
    "        tweets_list.append([tweet.user.username, tweet.id, tweet.date, tweet.content, \n",
    "                            tweet.url, tweet.likeCount, tweet.retweetCount, tweet.replyCount,\n",
    "                            tweet.quotedTweet, tweet.quoteCount, tweet.outlinks])\n",
    "\n",
    "    # Creating a dataframe from the tweets list above\n",
    "    tweets_df = pd.DataFrame(tweets_list, columns=[\"username\", \"id\", \"date\", \"content\",\n",
    "                                                  \"url\", \"likecount\", \"retweetcount\", \"replycount\",\n",
    "                                                  \"quotedTweet\", \"quoteCount\", \"outlinks\"])\n",
    "    \n",
    "    print(tweets_df.shape)\n",
    "    \n",
    "    return tweets_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining the account name\n",
    "accounts = [\"greglovesmovies\"]\n",
    "for account in accounts:\n",
    "\n",
    "    df_account = get_tweets(username = account)\n",
    "\n",
    "    time.sleep(6.66)\n",
    "\n",
    "    #exporting as an html file\n",
    "    df_account.to_csv(f\"tweets-ceo-raw-{account}.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#geting the file names\n",
    "filenames = glob.glob(\"tweets-ceo-raw-*.csv\")\n",
    "print(len(filenames), \"\", filenames)\n",
    "\n",
    "#combining files\n",
    "dataframes = [pd.read_csv(filename) for filename in filenames]\n",
    "df = pd.concat(dataframes)\n",
    "df.shape\n",
    "\n",
    "#generating the final file\n",
    "df.to_csv(\"tweets-ceo.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
